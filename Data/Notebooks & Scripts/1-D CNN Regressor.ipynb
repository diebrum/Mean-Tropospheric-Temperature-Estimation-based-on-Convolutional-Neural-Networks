{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas necessárias\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten,Dropout,LeakyReLU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import LeakyReLU\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando os dados \n",
    "\n",
    "X=np.loadtxt('inputs.txt') #Input para treinamento e teste da CNN\n",
    "y=np.loadtxt('targets.txt') #Target para treinamento e teste da CNN\n",
    "\n",
    "#By max normalization\n",
    "\n",
    "X[:,0]=X[:,0]/np.max(X[:,0])\n",
    "X[:,1]=X[:,1]/np.max(X[:,1])\n",
    "y=y/np.max(y)\n",
    "\n",
    "#Min-Max Normalization\n",
    "\n",
    "#X[:,0]=(np.max(X[:,0])-np.min(X[:,0]))/X[:,0]\n",
    "#X[:,1]=(np.max(X[:,1])-np.min(X[:,1]))/X[:,1]\n",
    "#y=(np.max(y)-np.min(y))/y\n",
    "\n",
    "#Adaptação para que o algoritmo reconheça os dados de entrada\n",
    "x = X.reshape(X.shape[0], X.shape[1], 1) \n",
    "\n",
    "#Caso optes por dividir os dados em treinamento e teste é só remover a \"#\" e especificar o tamanho da base de dados de teste\n",
    "#xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.10) \n",
    "\n",
    "#Mesmo procedimento acima, porém estes serão os dados em que os modelos serão aplicados\n",
    "\n",
    "X1=np.loadtxt('pred.txt') #entrada para teste do modelo\n",
    "y1=np.loadtxt('label.txt') #saídas esperadas na estapa teste\n",
    "X1[:,0]=X1[:,0]/np.max(X1[:,0])\n",
    "X1[:,1]=X1[:,1]/np.max(X1[:,1])\n",
    "y1=y1/np.max(y1)\n",
    "\n",
    "#X1[:,0]=(np.max(X1[:,0])-np.min(X1[:,0]))/X1[:,0]\n",
    "#X1[:,1]=(np.max(X1[:,1])-np.min(X1[:,1]))/X1[:,1]\n",
    "#y1=(np.max(y1)-np.min(y1))/y1\n",
    "x1=X1.reshape(X1.shape[0],X1.shape[1],1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo a arquitetura da CNN\n",
    "model = Sequential()\n",
    "#model.add(Conv1D(32, 2, activation=\"relu\", input_shape=(2, 1))) #substitui as 2 de baixo  (x,y) do mesmo jeito\n",
    "model.add(Conv1D(100, 2,  input_shape=(2, 1))) #Conv1D(x,y) x=n de neurionios por camadas |y= n de convoluções max5\n",
    "activation=keras.layers.LeakyReLU(alpha=0.2) #variar o valor do alpha de 0 até 1.\n",
    "#activation=keras.layers.LeakyReLU(alpha=0.1) #variar o valor do alpha de 0 até 1, deixa só os neurônios e limpa a debaixo\n",
    "\n",
    "\n",
    "#activation=sigmoid,relu,tanh,LeakyReLU (se alterar a função comenta a linha de cima e apaga a outra)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation=\"sigmoid\")) #(camada oculta)(x)numero de neuronios nessa camada  \n",
    "\n",
    "\n",
    "model.add(Dense(30, activation=\"sigmoid\")) #nova camada oculta (demora mais)\n",
    "\n",
    "\n",
    "model.add(Dense(1)) #camada de saída que é transformada da camada anterior\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "#loss=mse,mae #erro\n",
    "#optimizer=adam, SGD, RMSprop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "9005/9005 [==============================] - 10s 1ms/step - loss: 1.4630e-04\n",
      "Epoch 2/30\n",
      "9005/9005 [==============================] - 9s 982us/step - loss: 1.0290e-04\n",
      "Epoch 3/30\n",
      "9005/9005 [==============================] - 9s 1ms/step - loss: 1.0316e-04\n",
      "Epoch 4/30\n",
      "9005/9005 [==============================] - 9s 1ms/step - loss: 1.0178e-04\n",
      "Epoch 5/30\n",
      "9005/9005 [==============================] - 9s 1ms/step - loss: 1.0146e-04\n",
      "Epoch 6/30\n",
      "9005/9005 [==============================] - 9s 983us/step - loss: 1.0145e-04\n",
      "Epoch 7/30\n",
      "9005/9005 [==============================] - 9s 1ms/step - loss: 1.0046e-04\n",
      "Epoch 8/30\n",
      "9005/9005 [==============================] - 9s 1ms/step - loss: 9.8435e-05\n",
      "Epoch 9/30\n",
      "9005/9005 [==============================] - 8s 934us/step - loss: 9.9295e-05\n",
      "Epoch 10/30\n",
      "9005/9005 [==============================] - 9s 1ms/step - loss: 1.0009e-04\n",
      "Epoch 11/30\n",
      "9005/9005 [==============================] - 9s 953us/step - loss: 9.8409e-05\n",
      "Epoch 12/30\n",
      "9005/9005 [==============================] - 9s 1ms/step - loss: 9.8519e-05\n",
      "Epoch 13/30\n",
      "9005/9005 [==============================] - 9s 986us/step - loss: 9.6830e-05\n",
      "Epoch 14/30\n",
      "9005/9005 [==============================] - 9s 1ms/step - loss: 9.5998e-05\n",
      "Epoch 15/30\n",
      "9005/9005 [==============================] - 9s 1ms/step - loss: 9.6305e-05\n",
      "Epoch 16/30\n",
      "9005/9005 [==============================] - 13s 1ms/step - loss: 9.7389e-05\n",
      "Epoch 17/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.4592e-05\n",
      "Epoch 18/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.3579e-05: 0s - loss: 9.401\n",
      "Epoch 19/30\n",
      "9005/9005 [==============================] - 15s 2ms/step - loss: 9.3021e-05: \n",
      "Epoch 20/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.3875e-05\n",
      "Epoch 21/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.2747e-05\n",
      "Epoch 22/30\n",
      "9005/9005 [==============================] - 17s 2ms/step - loss: 9.2472e-05\n",
      "Epoch 23/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.2575e-05\n",
      "Epoch 24/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.2376e-05\n",
      "Epoch 25/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.3074e-05\n",
      "Epoch 26/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.0794e-05\n",
      "Epoch 27/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.2337e-05\n",
      "Epoch 28/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.1095e-05\n",
      "Epoch 29/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.1947e-05\n",
      "Epoch 30/30\n",
      "9005/9005 [==============================] - 16s 2ms/step - loss: 9.0784e-05: 0s - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c5d9d92748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#O método fit vai rodar o treinamento para um determinado número de épocas\n",
    "#batch_size=atualiza os pesos a cada pacote de tamanho 10\n",
    "model.fit(x, y, batch_size=10,epochs=30, verbose=1) #metodo de treinamento|x,y|(pedaço dos dados de treino)|epochs alterável\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O método predict vai aplicar seu modelo aos dados novos\n",
    "\n",
    "TM=model.predict(x1) #temperatura média \n",
    "\n",
    "#Métricas de avaliação normalmente utilizadas\n",
    "#TESTE\n",
    "mse = mean_squared_error(y1, TM) #erro médio quadratico (y1=dado real)\n",
    "rmse=np.sqrt(mse)#raiz do erro médio quadratico\n",
    "r2=r2_score(y1,TM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019140446983583585"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse #valor do rmse do TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como salvar seu modelo para que seja usado posteriormente\n",
    "\n",
    "model.save('model18.h5')\n",
    "\n",
    "#Salvar o resultado obtido na etapa de predição\n",
    "\n",
    "np.savetxt('model18.txt',TM,fmt='%.8f') #vai salvar os valores de TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 1, 100)            300       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 505       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                180       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 1,016\n",
      "Trainable params: 1,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Resumo do modelo \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como carregar um modelo já existente\n",
    "model = keras.models.load_model('model1.h5') #para análise de novas predições "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260.8212318477716"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(y1)*300 #y1 os dados de tm reais np=biblioteca para manipulaçao matematicas\n",
    "#calcula o valor minimo dos dados de tm reais voltando para escala real dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254.67193722724915"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(TM)*300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(y1)*300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290.38896560668945"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(TM)*300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90049, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X) # quantas dimensões tem os dados\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
